{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import mean_absolute_error,r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import random\n",
    "# fixing random seed for reproducibility\n",
    "random.seed(200216758)\n",
    "np.random.seed(200216758)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the MRI+MMSE dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ST101SV</th>\n",
       "      <th>ST102CV</th>\n",
       "      <th>ST102SA</th>\n",
       "      <th>ST102TA</th>\n",
       "      <th>ST102TS</th>\n",
       "      <th>ST103CV</th>\n",
       "      <th>ST103SA</th>\n",
       "      <th>ST103TA</th>\n",
       "      <th>ST103TS</th>\n",
       "      <th>ST104CV</th>\n",
       "      <th>...</th>\n",
       "      <th>ST99SA</th>\n",
       "      <th>ST99TA</th>\n",
       "      <th>ST99TS</th>\n",
       "      <th>ST9SV</th>\n",
       "      <th>MMSCORE_sc</th>\n",
       "      <th>MMSCORE_m06</th>\n",
       "      <th>MMSCORE_m12</th>\n",
       "      <th>MMSCORE_m24</th>\n",
       "      <th>MMSCORE_m36</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1578</td>\n",
       "      <td>2862</td>\n",
       "      <td>1312</td>\n",
       "      <td>2.065</td>\n",
       "      <td>0.609</td>\n",
       "      <td>2305</td>\n",
       "      <td>763</td>\n",
       "      <td>2.650</td>\n",
       "      <td>0.795</td>\n",
       "      <td>2934</td>\n",
       "      <td>...</td>\n",
       "      <td>3387</td>\n",
       "      <td>2.911</td>\n",
       "      <td>0.660</td>\n",
       "      <td>1623</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1102</td>\n",
       "      <td>3339</td>\n",
       "      <td>1386</td>\n",
       "      <td>2.297</td>\n",
       "      <td>0.702</td>\n",
       "      <td>1621</td>\n",
       "      <td>631</td>\n",
       "      <td>2.166</td>\n",
       "      <td>0.760</td>\n",
       "      <td>2517</td>\n",
       "      <td>...</td>\n",
       "      <td>3046</td>\n",
       "      <td>2.850</td>\n",
       "      <td>0.714</td>\n",
       "      <td>1296</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1226</td>\n",
       "      <td>2719</td>\n",
       "      <td>1477</td>\n",
       "      <td>1.781</td>\n",
       "      <td>0.538</td>\n",
       "      <td>1813</td>\n",
       "      <td>622</td>\n",
       "      <td>2.409</td>\n",
       "      <td>0.778</td>\n",
       "      <td>3397</td>\n",
       "      <td>...</td>\n",
       "      <td>2832</td>\n",
       "      <td>2.735</td>\n",
       "      <td>0.617</td>\n",
       "      <td>1998</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>744</td>\n",
       "      <td>3456</td>\n",
       "      <td>1748</td>\n",
       "      <td>1.960</td>\n",
       "      <td>0.620</td>\n",
       "      <td>1792</td>\n",
       "      <td>623</td>\n",
       "      <td>2.496</td>\n",
       "      <td>0.776</td>\n",
       "      <td>3106</td>\n",
       "      <td>...</td>\n",
       "      <td>2692</td>\n",
       "      <td>3.025</td>\n",
       "      <td>0.596</td>\n",
       "      <td>1493</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>908</td>\n",
       "      <td>2741</td>\n",
       "      <td>1216</td>\n",
       "      <td>2.228</td>\n",
       "      <td>0.612</td>\n",
       "      <td>2095</td>\n",
       "      <td>753</td>\n",
       "      <td>2.518</td>\n",
       "      <td>0.884</td>\n",
       "      <td>3696</td>\n",
       "      <td>...</td>\n",
       "      <td>3375</td>\n",
       "      <td>2.736</td>\n",
       "      <td>0.697</td>\n",
       "      <td>1997</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ST101SV  ST102CV  ST102SA  ST102TA  ST102TS  ST103CV  ST103SA  ST103TA  \\\n",
       "0     1578     2862     1312    2.065    0.609     2305      763    2.650   \n",
       "1     1102     3339     1386    2.297    0.702     1621      631    2.166   \n",
       "2     1226     2719     1477    1.781    0.538     1813      622    2.409   \n",
       "3      744     3456     1748    1.960    0.620     1792      623    2.496   \n",
       "4      908     2741     1216    2.228    0.612     2095      753    2.518   \n",
       "\n",
       "   ST103TS  ST104CV  ...  ST99SA  ST99TA  ST99TS  ST9SV  MMSCORE_sc  \\\n",
       "0    0.795     2934  ...    3387   2.911   0.660   1623          29   \n",
       "1    0.760     2517  ...    3046   2.850   0.714   1296          29   \n",
       "2    0.778     3397  ...    2832   2.735   0.617   1998          28   \n",
       "3    0.776     3106  ...    2692   3.025   0.596   1493          30   \n",
       "4    0.884     3696  ...    3375   2.736   0.697   1997          26   \n",
       "\n",
       "   MMSCORE_m06  MMSCORE_m12  MMSCORE_m24  MMSCORE_m36  label  \n",
       "0           29           30           29           30     CN  \n",
       "1           29           28           30           29     CN  \n",
       "2           29           30           28           26     CN  \n",
       "3           29           30           29           30     CN  \n",
       "4           28           28           29           28     CN  \n",
       "\n",
       "[5 rows x 333 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mri_data_df = pd.read_csv(\"/Users/shrutidudwadkar/Documents/Dissertation/Final_Data+Code/MRI/Processed/mri_mmse.csv\") \n",
    "mri_data_df.drop(columns=['RID'], inplace=True)\n",
    "mri_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total  332  features. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mri_features = mri_data_df.columns.values.tolist()\n",
    "print(\"There are total \", len(mri_features)-1, \" features. \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of subjects across 3 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph = sns.countplot(x=\"label\", data=mri_data_df);\n",
    "for p in graph.patches: \n",
    "    height = p.get_height()\n",
    "    graph.text(p.get_x() + p.get_width()/2., height + 0.2, height, ha=\"center\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ST101SV</th>\n",
       "      <th>ST102CV</th>\n",
       "      <th>ST102SA</th>\n",
       "      <th>ST102TA</th>\n",
       "      <th>ST102TS</th>\n",
       "      <th>ST103CV</th>\n",
       "      <th>ST103SA</th>\n",
       "      <th>ST103TA</th>\n",
       "      <th>ST103TS</th>\n",
       "      <th>ST104CV</th>\n",
       "      <th>...</th>\n",
       "      <th>ST99SA</th>\n",
       "      <th>ST99TA</th>\n",
       "      <th>ST99TS</th>\n",
       "      <th>ST9SV</th>\n",
       "      <th>MMSCORE_sc</th>\n",
       "      <th>MMSCORE_m06</th>\n",
       "      <th>MMSCORE_m12</th>\n",
       "      <th>MMSCORE_m24</th>\n",
       "      <th>MMSCORE_m36</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1578</td>\n",
       "      <td>2862</td>\n",
       "      <td>1312</td>\n",
       "      <td>2.065</td>\n",
       "      <td>0.609</td>\n",
       "      <td>2305</td>\n",
       "      <td>763</td>\n",
       "      <td>2.650</td>\n",
       "      <td>0.795</td>\n",
       "      <td>2934</td>\n",
       "      <td>...</td>\n",
       "      <td>3387</td>\n",
       "      <td>2.911</td>\n",
       "      <td>0.660</td>\n",
       "      <td>1623</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1102</td>\n",
       "      <td>3339</td>\n",
       "      <td>1386</td>\n",
       "      <td>2.297</td>\n",
       "      <td>0.702</td>\n",
       "      <td>1621</td>\n",
       "      <td>631</td>\n",
       "      <td>2.166</td>\n",
       "      <td>0.760</td>\n",
       "      <td>2517</td>\n",
       "      <td>...</td>\n",
       "      <td>3046</td>\n",
       "      <td>2.850</td>\n",
       "      <td>0.714</td>\n",
       "      <td>1296</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1226</td>\n",
       "      <td>2719</td>\n",
       "      <td>1477</td>\n",
       "      <td>1.781</td>\n",
       "      <td>0.538</td>\n",
       "      <td>1813</td>\n",
       "      <td>622</td>\n",
       "      <td>2.409</td>\n",
       "      <td>0.778</td>\n",
       "      <td>3397</td>\n",
       "      <td>...</td>\n",
       "      <td>2832</td>\n",
       "      <td>2.735</td>\n",
       "      <td>0.617</td>\n",
       "      <td>1998</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>744</td>\n",
       "      <td>3456</td>\n",
       "      <td>1748</td>\n",
       "      <td>1.960</td>\n",
       "      <td>0.620</td>\n",
       "      <td>1792</td>\n",
       "      <td>623</td>\n",
       "      <td>2.496</td>\n",
       "      <td>0.776</td>\n",
       "      <td>3106</td>\n",
       "      <td>...</td>\n",
       "      <td>2692</td>\n",
       "      <td>3.025</td>\n",
       "      <td>0.596</td>\n",
       "      <td>1493</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>908</td>\n",
       "      <td>2741</td>\n",
       "      <td>1216</td>\n",
       "      <td>2.228</td>\n",
       "      <td>0.612</td>\n",
       "      <td>2095</td>\n",
       "      <td>753</td>\n",
       "      <td>2.518</td>\n",
       "      <td>0.884</td>\n",
       "      <td>3696</td>\n",
       "      <td>...</td>\n",
       "      <td>3375</td>\n",
       "      <td>2.736</td>\n",
       "      <td>0.697</td>\n",
       "      <td>1997</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 333 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ST101SV  ST102CV  ST102SA  ST102TA  ST102TS  ST103CV  ST103SA  ST103TA  \\\n",
       "0     1578     2862     1312    2.065    0.609     2305      763    2.650   \n",
       "1     1102     3339     1386    2.297    0.702     1621      631    2.166   \n",
       "2     1226     2719     1477    1.781    0.538     1813      622    2.409   \n",
       "3      744     3456     1748    1.960    0.620     1792      623    2.496   \n",
       "4      908     2741     1216    2.228    0.612     2095      753    2.518   \n",
       "\n",
       "   ST103TS  ST104CV  ...  ST99SA  ST99TA  ST99TS  ST9SV  MMSCORE_sc  \\\n",
       "0    0.795     2934  ...    3387   2.911   0.660   1623          29   \n",
       "1    0.760     2517  ...    3046   2.850   0.714   1296          29   \n",
       "2    0.778     3397  ...    2832   2.735   0.617   1998          28   \n",
       "3    0.776     3106  ...    2692   3.025   0.596   1493          30   \n",
       "4    0.884     3696  ...    3375   2.736   0.697   1997          26   \n",
       "\n",
       "   MMSCORE_m06  MMSCORE_m12  MMSCORE_m24  MMSCORE_m36  label  \n",
       "0           29           30           29           30      0  \n",
       "1           29           28           30           29      0  \n",
       "2           29           30           28           26      0  \n",
       "3           29           30           29           30      0  \n",
       "4           28           28           29           28      0  \n",
       "\n",
       "[5 rows x 333 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "mri_data_df['label']= encoder.fit_transform(mri_data_df['label'])\n",
    "mri_data_df['label'].unique()\n",
    "mri_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CN' 'Dementia' 'MCI']\n"
     ]
    }
   ],
   "source": [
    "print(encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mri, y_mri = np.split(mri_data_df.to_numpy(), [-1], axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into train and test data using 85:15 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mri, X_test_mri, y_train_mri, y_test_mri = train_test_split(X_mri, y_mri, test_size=0.15, random_state=44)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_mri = sc.fit_transform(X_train_mri)\n",
    "X_test_mri = sc.transform(X_test_mri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier using l1 penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.90      0.90        10\n",
      "         1.0       0.40      0.67      0.50         6\n",
      "         2.0       0.83      0.62      0.71        16\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.71      0.73      0.70        32\n",
      "weighted avg       0.77      0.72      0.73        32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrutidudwadkar/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "#classifier_mri = SGDClassifier(penalty='l1', alpha=0.09, max_iter=10e5, loss='log')\n",
    "classifier_mri = SGDClassifier(penalty='l1', alpha=0.03, max_iter=10e7, loss='log')\n",
    "classifier_mri.fit(X_train_mri, y_train_mri)\n",
    "y_pred = classifier_mri.predict(X_test_mri)\n",
    "\n",
    "print(\"Classification report: \")\n",
    "print(classification_report(y_test_mri , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71875\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test_mri, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score:  0.9142857142857143\n",
      "test score:  0.71875\n"
     ]
    }
   ],
   "source": [
    "train_score = classifier_mri.score(X_train_mri, y_train_mri)\n",
    "test_score = classifier_mri.score(X_test_mri, y_test_mri)\n",
    "coeff_used = np.sum(classifier_mri.coef_ != 0)\n",
    "\n",
    "print(\"training score: \", train_score)\n",
    "print(\"test score: \", test_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features used:  105\n"
     ]
    }
   ],
   "source": [
    "sel_cols = list(mri_data_df.columns[:-1][(classifier_mri.coef_!=0)[0]]) + list(mri_data_df.columns[:-1][(classifier_mri.coef_!=0)[1]]) + list(mri_data_df.columns[:-1][(classifier_mri.coef_!=0)[2]])\n",
    "sel_cols = list(dict.fromkeys(sel_cols))\n",
    "print(\"number of features used: \", len(sel_cols))\n",
    "rem_cols= ['MMSCORE_sc', 'MMSCORE_m06', 'MMSCORE_m12','MMSCORE_m24','MMSCORE_m36']\n",
    "sel_cols = list(set(sel_cols) - set(rem_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ST54SA</th>\n",
       "      <th>ST72TA</th>\n",
       "      <th>ST118TA</th>\n",
       "      <th>ST40SA</th>\n",
       "      <th>ST51TA</th>\n",
       "      <th>ST31SA</th>\n",
       "      <th>ST112SV</th>\n",
       "      <th>ST121SA</th>\n",
       "      <th>ST46TA</th>\n",
       "      <th>ST25CV</th>\n",
       "      <th>...</th>\n",
       "      <th>ST54CV</th>\n",
       "      <th>ST1SV</th>\n",
       "      <th>ST13TS</th>\n",
       "      <th>ST17SV</th>\n",
       "      <th>ST68SV</th>\n",
       "      <th>ST106TA</th>\n",
       "      <th>ST103TS</th>\n",
       "      <th>ST123CV</th>\n",
       "      <th>ST58TS</th>\n",
       "      <th>ST11SV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>889</td>\n",
       "      <td>2.339</td>\n",
       "      <td>2.422</td>\n",
       "      <td>2832</td>\n",
       "      <td>2.079</td>\n",
       "      <td>6463</td>\n",
       "      <td>4816</td>\n",
       "      <td>368</td>\n",
       "      <td>2.609</td>\n",
       "      <td>540</td>\n",
       "      <td>...</td>\n",
       "      <td>2941</td>\n",
       "      <td>22015</td>\n",
       "      <td>0.516</td>\n",
       "      <td>54024</td>\n",
       "      <td>51</td>\n",
       "      <td>2.099</td>\n",
       "      <td>0.795</td>\n",
       "      <td>7207</td>\n",
       "      <td>0.634</td>\n",
       "      <td>505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>472</td>\n",
       "      <td>2.345</td>\n",
       "      <td>2.461</td>\n",
       "      <td>2024</td>\n",
       "      <td>2.284</td>\n",
       "      <td>3846</td>\n",
       "      <td>4133</td>\n",
       "      <td>251</td>\n",
       "      <td>1.915</td>\n",
       "      <td>441</td>\n",
       "      <td>...</td>\n",
       "      <td>1789</td>\n",
       "      <td>15665</td>\n",
       "      <td>0.534</td>\n",
       "      <td>37451</td>\n",
       "      <td>30</td>\n",
       "      <td>2.048</td>\n",
       "      <td>0.760</td>\n",
       "      <td>5794</td>\n",
       "      <td>0.724</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570</td>\n",
       "      <td>2.404</td>\n",
       "      <td>2.397</td>\n",
       "      <td>2804</td>\n",
       "      <td>1.972</td>\n",
       "      <td>3672</td>\n",
       "      <td>4139</td>\n",
       "      <td>259</td>\n",
       "      <td>2.477</td>\n",
       "      <td>584</td>\n",
       "      <td>...</td>\n",
       "      <td>1953</td>\n",
       "      <td>21483</td>\n",
       "      <td>0.583</td>\n",
       "      <td>43883</td>\n",
       "      <td>43</td>\n",
       "      <td>2.162</td>\n",
       "      <td>0.778</td>\n",
       "      <td>7397</td>\n",
       "      <td>0.673</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>767</td>\n",
       "      <td>2.586</td>\n",
       "      <td>2.261</td>\n",
       "      <td>2702</td>\n",
       "      <td>1.932</td>\n",
       "      <td>4797</td>\n",
       "      <td>4726</td>\n",
       "      <td>304</td>\n",
       "      <td>2.668</td>\n",
       "      <td>574</td>\n",
       "      <td>...</td>\n",
       "      <td>2490</td>\n",
       "      <td>19150</td>\n",
       "      <td>0.425</td>\n",
       "      <td>42210</td>\n",
       "      <td>11</td>\n",
       "      <td>2.534</td>\n",
       "      <td>0.776</td>\n",
       "      <td>6222</td>\n",
       "      <td>0.674</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>745</td>\n",
       "      <td>2.328</td>\n",
       "      <td>2.218</td>\n",
       "      <td>2837</td>\n",
       "      <td>2.366</td>\n",
       "      <td>4447</td>\n",
       "      <td>4080</td>\n",
       "      <td>366</td>\n",
       "      <td>2.390</td>\n",
       "      <td>491</td>\n",
       "      <td>...</td>\n",
       "      <td>2333</td>\n",
       "      <td>21086</td>\n",
       "      <td>0.493</td>\n",
       "      <td>56871</td>\n",
       "      <td>47</td>\n",
       "      <td>2.213</td>\n",
       "      <td>0.884</td>\n",
       "      <td>6836</td>\n",
       "      <td>0.796</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>579</td>\n",
       "      <td>1.850</td>\n",
       "      <td>2.424</td>\n",
       "      <td>2813</td>\n",
       "      <td>2.450</td>\n",
       "      <td>4213</td>\n",
       "      <td>5238</td>\n",
       "      <td>328</td>\n",
       "      <td>2.361</td>\n",
       "      <td>739</td>\n",
       "      <td>...</td>\n",
       "      <td>2223</td>\n",
       "      <td>24300</td>\n",
       "      <td>0.472</td>\n",
       "      <td>45914</td>\n",
       "      <td>19</td>\n",
       "      <td>2.201</td>\n",
       "      <td>0.787</td>\n",
       "      <td>6798</td>\n",
       "      <td>0.769</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>750</td>\n",
       "      <td>2.304</td>\n",
       "      <td>2.188</td>\n",
       "      <td>2607</td>\n",
       "      <td>1.879</td>\n",
       "      <td>5305</td>\n",
       "      <td>4572</td>\n",
       "      <td>317</td>\n",
       "      <td>2.396</td>\n",
       "      <td>518</td>\n",
       "      <td>...</td>\n",
       "      <td>2479</td>\n",
       "      <td>20872</td>\n",
       "      <td>0.494</td>\n",
       "      <td>38362</td>\n",
       "      <td>42</td>\n",
       "      <td>2.087</td>\n",
       "      <td>0.874</td>\n",
       "      <td>7142</td>\n",
       "      <td>0.642</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>907</td>\n",
       "      <td>2.239</td>\n",
       "      <td>2.444</td>\n",
       "      <td>3289</td>\n",
       "      <td>2.272</td>\n",
       "      <td>3713</td>\n",
       "      <td>5250</td>\n",
       "      <td>357</td>\n",
       "      <td>2.337</td>\n",
       "      <td>670</td>\n",
       "      <td>...</td>\n",
       "      <td>2839</td>\n",
       "      <td>26053</td>\n",
       "      <td>0.494</td>\n",
       "      <td>55407</td>\n",
       "      <td>34</td>\n",
       "      <td>2.215</td>\n",
       "      <td>0.890</td>\n",
       "      <td>8028</td>\n",
       "      <td>0.684</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>510</td>\n",
       "      <td>2.573</td>\n",
       "      <td>2.458</td>\n",
       "      <td>2250</td>\n",
       "      <td>2.312</td>\n",
       "      <td>3900</td>\n",
       "      <td>3300</td>\n",
       "      <td>246</td>\n",
       "      <td>2.633</td>\n",
       "      <td>632</td>\n",
       "      <td>...</td>\n",
       "      <td>2018</td>\n",
       "      <td>18744</td>\n",
       "      <td>0.584</td>\n",
       "      <td>43895</td>\n",
       "      <td>27</td>\n",
       "      <td>2.450</td>\n",
       "      <td>0.744</td>\n",
       "      <td>6734</td>\n",
       "      <td>0.765</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>521</td>\n",
       "      <td>2.502</td>\n",
       "      <td>2.614</td>\n",
       "      <td>3172</td>\n",
       "      <td>2.510</td>\n",
       "      <td>4309</td>\n",
       "      <td>4388</td>\n",
       "      <td>322</td>\n",
       "      <td>2.644</td>\n",
       "      <td>722</td>\n",
       "      <td>...</td>\n",
       "      <td>1535</td>\n",
       "      <td>18408</td>\n",
       "      <td>0.484</td>\n",
       "      <td>52966</td>\n",
       "      <td>32</td>\n",
       "      <td>2.558</td>\n",
       "      <td>0.939</td>\n",
       "      <td>7590</td>\n",
       "      <td>0.651</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ST54SA  ST72TA  ST118TA  ST40SA  ST51TA  ST31SA  ST112SV  ST121SA  \\\n",
       "0       889   2.339    2.422    2832   2.079    6463     4816      368   \n",
       "1       472   2.345    2.461    2024   2.284    3846     4133      251   \n",
       "2       570   2.404    2.397    2804   1.972    3672     4139      259   \n",
       "3       767   2.586    2.261    2702   1.932    4797     4726      304   \n",
       "4       745   2.328    2.218    2837   2.366    4447     4080      366   \n",
       "..      ...     ...      ...     ...     ...     ...      ...      ...   \n",
       "202     579   1.850    2.424    2813   2.450    4213     5238      328   \n",
       "203     750   2.304    2.188    2607   1.879    5305     4572      317   \n",
       "204     907   2.239    2.444    3289   2.272    3713     5250      357   \n",
       "205     510   2.573    2.458    2250   2.312    3900     3300      246   \n",
       "206     521   2.502    2.614    3172   2.510    4309     4388      322   \n",
       "\n",
       "     ST46TA  ST25CV  ...  ST54CV  ST1SV  ST13TS  ST17SV  ST68SV  ST106TA  \\\n",
       "0     2.609     540  ...    2941  22015   0.516   54024      51    2.099   \n",
       "1     1.915     441  ...    1789  15665   0.534   37451      30    2.048   \n",
       "2     2.477     584  ...    1953  21483   0.583   43883      43    2.162   \n",
       "3     2.668     574  ...    2490  19150   0.425   42210      11    2.534   \n",
       "4     2.390     491  ...    2333  21086   0.493   56871      47    2.213   \n",
       "..      ...     ...  ...     ...    ...     ...     ...     ...      ...   \n",
       "202   2.361     739  ...    2223  24300   0.472   45914      19    2.201   \n",
       "203   2.396     518  ...    2479  20872   0.494   38362      42    2.087   \n",
       "204   2.337     670  ...    2839  26053   0.494   55407      34    2.215   \n",
       "205   2.633     632  ...    2018  18744   0.584   43895      27    2.450   \n",
       "206   2.644     722  ...    1535  18408   0.484   52966      32    2.558   \n",
       "\n",
       "     ST103TS  ST123CV  ST58TS  ST11SV  \n",
       "0      0.795     7207   0.634     505  \n",
       "1      0.760     5794   0.724     256  \n",
       "2      0.778     7397   0.673     549  \n",
       "3      0.776     6222   0.674     523  \n",
       "4      0.884     6836   0.796     316  \n",
       "..       ...      ...     ...     ...  \n",
       "202    0.787     6798   0.769     618  \n",
       "203    0.874     7142   0.642     364  \n",
       "204    0.890     8028   0.684     578  \n",
       "205    0.744     6734   0.765     403  \n",
       "206    0.939     7590   0.651     530  \n",
       "\n",
       "[207 rows x 100 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mri_data_fusion_df = mri_data_df[sel_cols]\n",
    "mri_data_fusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8120799339549339\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_test_mri, classifier_mri.predict_proba(X_test_mri), multi_class='ovr')\n",
    "print(\"AUC: \", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.6123724356957945\n"
     ]
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_test_mri, y_pred))\n",
    "print(\"RMSE: \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the PET+MMSE dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CP_MEAN</th>\n",
       "      <th>CP_MEDIAN</th>\n",
       "      <th>CP_MODE</th>\n",
       "      <th>CP_MIN</th>\n",
       "      <th>CP_MAX</th>\n",
       "      <th>CP_STDEV</th>\n",
       "      <th>AL_MEAN</th>\n",
       "      <th>AL_MEDIAN</th>\n",
       "      <th>AL_MODE</th>\n",
       "      <th>AL_MIN</th>\n",
       "      <th>...</th>\n",
       "      <th>TR_MODE</th>\n",
       "      <th>TR_MIN</th>\n",
       "      <th>TR_MAX</th>\n",
       "      <th>TR_STDEV</th>\n",
       "      <th>MMSCORE_sc</th>\n",
       "      <th>MMSCORE_m06</th>\n",
       "      <th>MMSCORE_m12</th>\n",
       "      <th>MMSCORE_m24</th>\n",
       "      <th>MMSCORE_m36</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.42132</td>\n",
       "      <td>1.46006</td>\n",
       "      <td>1.010860</td>\n",
       "      <td>1.010860</td>\n",
       "      <td>1.59085</td>\n",
       "      <td>0.135861</td>\n",
       "      <td>1.35493</td>\n",
       "      <td>1.38456</td>\n",
       "      <td>1.062030</td>\n",
       "      <td>1.062030</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965637</td>\n",
       "      <td>0.965637</td>\n",
       "      <td>1.30464</td>\n",
       "      <td>0.068228</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.35138</td>\n",
       "      <td>1.43394</td>\n",
       "      <td>0.671526</td>\n",
       "      <td>0.671526</td>\n",
       "      <td>1.71550</td>\n",
       "      <td>0.242687</td>\n",
       "      <td>1.22372</td>\n",
       "      <td>1.22393</td>\n",
       "      <td>1.014400</td>\n",
       "      <td>1.014400</td>\n",
       "      <td>...</td>\n",
       "      <td>1.056220</td>\n",
       "      <td>1.056220</td>\n",
       "      <td>1.36527</td>\n",
       "      <td>0.074463</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.63455</td>\n",
       "      <td>1.64769</td>\n",
       "      <td>1.234410</td>\n",
       "      <td>1.234410</td>\n",
       "      <td>1.86328</td>\n",
       "      <td>0.133708</td>\n",
       "      <td>1.52068</td>\n",
       "      <td>1.52008</td>\n",
       "      <td>1.142760</td>\n",
       "      <td>1.142760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788854</td>\n",
       "      <td>0.788854</td>\n",
       "      <td>1.37939</td>\n",
       "      <td>0.140904</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.37415</td>\n",
       "      <td>1.41541</td>\n",
       "      <td>0.926628</td>\n",
       "      <td>0.926628</td>\n",
       "      <td>1.65001</td>\n",
       "      <td>0.164401</td>\n",
       "      <td>1.47392</td>\n",
       "      <td>1.47777</td>\n",
       "      <td>0.997425</td>\n",
       "      <td>0.997425</td>\n",
       "      <td>...</td>\n",
       "      <td>1.022780</td>\n",
       "      <td>1.022780</td>\n",
       "      <td>1.39271</td>\n",
       "      <td>0.081254</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.43045</td>\n",
       "      <td>1.47362</td>\n",
       "      <td>0.910827</td>\n",
       "      <td>0.910827</td>\n",
       "      <td>1.68188</td>\n",
       "      <td>0.191474</td>\n",
       "      <td>1.37903</td>\n",
       "      <td>1.40453</td>\n",
       "      <td>0.874430</td>\n",
       "      <td>0.874430</td>\n",
       "      <td>...</td>\n",
       "      <td>1.100920</td>\n",
       "      <td>1.100920</td>\n",
       "      <td>1.37395</td>\n",
       "      <td>0.059151</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>CN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CP_MEAN  CP_MEDIAN   CP_MODE    CP_MIN   CP_MAX  CP_STDEV  AL_MEAN  \\\n",
       "0  1.42132    1.46006  1.010860  1.010860  1.59085  0.135861  1.35493   \n",
       "1  1.35138    1.43394  0.671526  0.671526  1.71550  0.242687  1.22372   \n",
       "2  1.63455    1.64769  1.234410  1.234410  1.86328  0.133708  1.52068   \n",
       "3  1.37415    1.41541  0.926628  0.926628  1.65001  0.164401  1.47392   \n",
       "4  1.43045    1.47362  0.910827  0.910827  1.68188  0.191474  1.37903   \n",
       "\n",
       "   AL_MEDIAN   AL_MODE    AL_MIN  ...   TR_MODE    TR_MIN   TR_MAX  TR_STDEV  \\\n",
       "0    1.38456  1.062030  1.062030  ...  0.965637  0.965637  1.30464  0.068228   \n",
       "1    1.22393  1.014400  1.014400  ...  1.056220  1.056220  1.36527  0.074463   \n",
       "2    1.52008  1.142760  1.142760  ...  0.788854  0.788854  1.37939  0.140904   \n",
       "3    1.47777  0.997425  0.997425  ...  1.022780  1.022780  1.39271  0.081254   \n",
       "4    1.40453  0.874430  0.874430  ...  1.100920  1.100920  1.37395  0.059151   \n",
       "\n",
       "   MMSCORE_sc  MMSCORE_m06  MMSCORE_m12  MMSCORE_m24  MMSCORE_m36  label  \n",
       "0          29           29           30           29           30     CN  \n",
       "1          29           29           28           30           29     CN  \n",
       "2          28           29           30           28           26     CN  \n",
       "3          30           29           30           29           30     CN  \n",
       "4          26           28           28           29           28     CN  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pet_data_df = pd.read_csv(\"/Users/shrutidudwadkar/Documents/Dissertation/Final_Data+Code/PET/Processed/pet_mmse.csv\") \n",
    "pet_data_df.drop(columns=['RID'], inplace=True)\n",
    "\n",
    "pet_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total  35  features. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pet_features = pet_data_df.columns.values.tolist()\n",
    "print(\"There are total \", len(pet_features)-1, \" features. \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "pet_data_df['label']= encoder.fit_transform(pet_data_df['label'])\n",
    "pet_data_df['label'].unique()\n",
    "pet_data_df.head()\n",
    "pet_data_df_fi =pet_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selction using Univariate Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pet_data_df.iloc[:,0:35]\n",
    "y = pet_data_df.iloc[:,-1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestfeatures = SelectKBest(score_func=chi2, k=14)\n",
    "fit = bestfeatures.fit(X, y)\n",
    "dfscores = pd.DataFrame(fit.scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Specs      Score\n",
      "34  MMSCORE_m36  59.133971\n",
      "33  MMSCORE_m24  38.577862\n",
      "32  MMSCORE_m12  16.494915\n",
      "31  MMSCORE_m06  11.221813\n",
      "30   MMSCORE_sc   4.554861\n",
      "4        CP_MAX   1.216650\n",
      "1     CP_MEDIAN   1.054037\n",
      "0       CP_MEAN   1.009330\n",
      "10       AL_MAX   0.914336\n",
      "7     AL_MEDIAN   0.740034\n"
     ]
    }
   ],
   "source": [
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MMSCORE_m36</th>\n",
       "      <th>MMSCORE_m24</th>\n",
       "      <th>MMSCORE_m12</th>\n",
       "      <th>MMSCORE_m06</th>\n",
       "      <th>MMSCORE_sc</th>\n",
       "      <th>CP_MAX</th>\n",
       "      <th>CP_MEDIAN</th>\n",
       "      <th>CP_MEAN</th>\n",
       "      <th>AL_MAX</th>\n",
       "      <th>AL_MEDIAN</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>1.59085</td>\n",
       "      <td>1.46006</td>\n",
       "      <td>1.42132</td>\n",
       "      <td>1.48234</td>\n",
       "      <td>1.38456</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>1.71550</td>\n",
       "      <td>1.43394</td>\n",
       "      <td>1.35138</td>\n",
       "      <td>1.39319</td>\n",
       "      <td>1.22393</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>1.86328</td>\n",
       "      <td>1.64769</td>\n",
       "      <td>1.63455</td>\n",
       "      <td>1.71677</td>\n",
       "      <td>1.52008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>1.65001</td>\n",
       "      <td>1.41541</td>\n",
       "      <td>1.37415</td>\n",
       "      <td>1.67836</td>\n",
       "      <td>1.47777</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>1.68188</td>\n",
       "      <td>1.47362</td>\n",
       "      <td>1.43045</td>\n",
       "      <td>1.55640</td>\n",
       "      <td>1.40453</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MMSCORE_m36  MMSCORE_m24  MMSCORE_m12  MMSCORE_m06  MMSCORE_sc   CP_MAX  \\\n",
       "0           30           29           30           29          29  1.59085   \n",
       "1           29           30           28           29          29  1.71550   \n",
       "2           26           28           30           29          28  1.86328   \n",
       "3           30           29           30           29          30  1.65001   \n",
       "4           28           29           28           28          26  1.68188   \n",
       "\n",
       "   CP_MEDIAN  CP_MEAN   AL_MAX  AL_MEDIAN  label  \n",
       "0    1.46006  1.42132  1.48234    1.38456      0  \n",
       "1    1.43394  1.35138  1.39319    1.22393      0  \n",
       "2    1.64769  1.63455  1.71677    1.52008      0  \n",
       "3    1.41541  1.37415  1.67836    1.47777      0  \n",
       "4    1.47362  1.43045  1.55640    1.40453      0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = featureScores.nlargest(10,'Score')['Specs'].tolist()\n",
    "columns.append('label')\n",
    "pet_data_df = pet_data_df[columns]\n",
    "pet_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MMSCORE_m36</th>\n",
       "      <th>MMSCORE_m24</th>\n",
       "      <th>MMSCORE_m12</th>\n",
       "      <th>MMSCORE_m06</th>\n",
       "      <th>MMSCORE_sc</th>\n",
       "      <th>CP_MAX</th>\n",
       "      <th>CP_MEDIAN</th>\n",
       "      <th>CP_MEAN</th>\n",
       "      <th>AL_MAX</th>\n",
       "      <th>AL_MEDIAN</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>1.59085</td>\n",
       "      <td>1.46006</td>\n",
       "      <td>1.42132</td>\n",
       "      <td>1.48234</td>\n",
       "      <td>1.384560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>1.71550</td>\n",
       "      <td>1.43394</td>\n",
       "      <td>1.35138</td>\n",
       "      <td>1.39319</td>\n",
       "      <td>1.223930</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>1.86328</td>\n",
       "      <td>1.64769</td>\n",
       "      <td>1.63455</td>\n",
       "      <td>1.71677</td>\n",
       "      <td>1.520080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>1.65001</td>\n",
       "      <td>1.41541</td>\n",
       "      <td>1.37415</td>\n",
       "      <td>1.67836</td>\n",
       "      <td>1.477770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>1.68188</td>\n",
       "      <td>1.47362</td>\n",
       "      <td>1.43045</td>\n",
       "      <td>1.55640</td>\n",
       "      <td>1.404530</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>1.53736</td>\n",
       "      <td>1.34343</td>\n",
       "      <td>1.32522</td>\n",
       "      <td>1.28098</td>\n",
       "      <td>1.154530</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>1.50612</td>\n",
       "      <td>1.31512</td>\n",
       "      <td>1.29116</td>\n",
       "      <td>1.44391</td>\n",
       "      <td>1.300910</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>1.51473</td>\n",
       "      <td>1.39244</td>\n",
       "      <td>1.33926</td>\n",
       "      <td>1.26802</td>\n",
       "      <td>1.159030</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>1.47965</td>\n",
       "      <td>1.31724</td>\n",
       "      <td>1.29768</td>\n",
       "      <td>1.08829</td>\n",
       "      <td>0.997788</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "      <td>1.66393</td>\n",
       "      <td>1.44226</td>\n",
       "      <td>1.40044</td>\n",
       "      <td>1.59802</td>\n",
       "      <td>1.406340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MMSCORE_m36  MMSCORE_m24  MMSCORE_m12  MMSCORE_m06  MMSCORE_sc   CP_MAX  \\\n",
       "0             30           29           30           29          29  1.59085   \n",
       "1             29           30           28           29          29  1.71550   \n",
       "2             26           28           30           29          28  1.86328   \n",
       "3             30           29           30           29          30  1.65001   \n",
       "4             28           29           28           28          26  1.68188   \n",
       "..           ...          ...          ...          ...         ...      ...   \n",
       "202           27           28           28           28          27  1.53736   \n",
       "203           30           30           30           29          29  1.50612   \n",
       "204           29           29           29           28          28  1.51473   \n",
       "205           24           22           26           26          28  1.47965   \n",
       "206           14           20           20           22          27  1.66393   \n",
       "\n",
       "     CP_MEDIAN  CP_MEAN   AL_MAX  AL_MEDIAN  label  \n",
       "0      1.46006  1.42132  1.48234   1.384560      0  \n",
       "1      1.43394  1.35138  1.39319   1.223930      0  \n",
       "2      1.64769  1.63455  1.71677   1.520080      0  \n",
       "3      1.41541  1.37415  1.67836   1.477770      0  \n",
       "4      1.47362  1.43045  1.55640   1.404530      0  \n",
       "..         ...      ...      ...        ...    ...  \n",
       "202    1.34343  1.32522  1.28098   1.154530      2  \n",
       "203    1.31512  1.29116  1.44391   1.300910      2  \n",
       "204    1.39244  1.33926  1.26802   1.159030      2  \n",
       "205    1.31724  1.29768  1.08829   0.997788      1  \n",
       "206    1.44226  1.40044  1.59802   1.406340      1  \n",
       "\n",
       "[207 rows x 11 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pet_data_fusion_df = pet_data_df\n",
    "pet_data_fusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pet, y_pet = np.split(pet_data_df.to_numpy(), [-1], axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset into train and test data using 85:15 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pet, X_test_pet, y_train_pet, y_test_pet = train_test_split(X_pet, y_pet, test_size=0.15, random_state=44)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_pet = min_max_scaler.fit_transform(X_train_pet)\n",
    "X_test_pet = min_max_scaler.transform(X_test_pet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian NB Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.80      0.70        10\n",
      "         1.0       0.75      1.00      0.86         6\n",
      "         2.0       0.82      0.56      0.67        16\n",
      "\n",
      "    accuracy                           0.72        32\n",
      "   macro avg       0.73      0.79      0.74        32\n",
      "weighted avg       0.74      0.72      0.71        32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrutidudwadkar/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB().fit(X_train_pet, y_train_pet)\n",
    "gnb_predictions = gnb.predict(X_test_pet)\n",
    "\n",
    "print(\"Classification report: \")\n",
    "print(classification_report(y_test_pet , gnb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.71875\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test_pet, gnb_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.8352497329059828\n"
     ]
    }
   ],
   "source": [
    "auc = roc_auc_score(y_test_pet, gnb.predict_proba(X_test_pet), multi_class='ovr')\n",
    "print(\"AUC: \", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.9682458365518543\n"
     ]
    }
   ],
   "source": [
    "rmse = sqrt(mean_squared_error(y_test_pet , gnb_predictions))\n",
    "print(\"RMSE: \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Late fusion or Classifier fusion using Voting classifier\n",
    "\n",
    "Reference taken from https://stackoverflow.com/questions/45074579/votingclassifier-different-feature-sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def fit_estimators(classifiers, X_list, y, sample_weights = None):\n",
    "\n",
    "    le_ = LabelEncoder()\n",
    "    le_.fit(y)\n",
    "    \n",
    "    estimators_ = [clf.fit(X, y) if sample_weights is None else clf.fit(X, y, sample_weights) for clf, X in zip([clf for _, clf in classifiers], X_list)]\n",
    "\n",
    "    return estimators_, le_\n",
    "\n",
    "\n",
    "def predict_from_estimators(estimators, label_encoder, X_list, weights = [1, 1]):\n",
    "\n",
    "    # Soft voting approach\n",
    "\n",
    "    pred1 = np.asarray([clf.predict_proba(X) for clf, X in zip(estimators, X_list)])\n",
    "    pred2 = np.average(pred1, axis=0, weights=weights)\n",
    "    \n",
    "    pred = np.argmax(pred2, axis=1)\n",
    "    \n",
    "    # Convert the int predictions to actual labels\n",
    "    return label_encoder.inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_list = [X_train_mri, X_train_pet]\n",
    "X_test_list = [X_test_mri, X_test_pet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [('mri', classifier_mri), ('pet', gnb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrutidudwadkar/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/shrutidudwadkar/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/Users/shrutidudwadkar/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "fitted_estimators, label_encoder = fit_estimators(classifiers, X_train_list, y_train_mri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_combine = predict_from_estimators(fitted_estimators, label_encoder, X_test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.80      0.70        10\n",
      "         1.0       0.71      0.83      0.77         6\n",
      "         2.0       0.75      0.56      0.64        16\n",
      "\n",
      "    accuracy                           0.69        32\n",
      "   macro avg       0.69      0.73      0.70        32\n",
      "weighted avg       0.70      0.69      0.68        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification report: \")\n",
    "print(classification_report(y_test_pet , y_pred_combine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6875\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test_mri, y_pred_combine))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early fusion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ST54SA</th>\n",
       "      <th>ST72TA</th>\n",
       "      <th>ST118TA</th>\n",
       "      <th>ST40SA</th>\n",
       "      <th>ST51TA</th>\n",
       "      <th>ST31SA</th>\n",
       "      <th>ST112SV</th>\n",
       "      <th>ST121SA</th>\n",
       "      <th>ST46TA</th>\n",
       "      <th>ST25CV</th>\n",
       "      <th>...</th>\n",
       "      <th>MMSCORE_m24</th>\n",
       "      <th>MMSCORE_m12</th>\n",
       "      <th>MMSCORE_m06</th>\n",
       "      <th>MMSCORE_sc</th>\n",
       "      <th>CP_MAX</th>\n",
       "      <th>CP_MEDIAN</th>\n",
       "      <th>CP_MEAN</th>\n",
       "      <th>AL_MAX</th>\n",
       "      <th>AL_MEDIAN</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>889</td>\n",
       "      <td>2.339</td>\n",
       "      <td>2.422</td>\n",
       "      <td>2832</td>\n",
       "      <td>2.079</td>\n",
       "      <td>6463</td>\n",
       "      <td>4816</td>\n",
       "      <td>368</td>\n",
       "      <td>2.609</td>\n",
       "      <td>540</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>1.59085</td>\n",
       "      <td>1.46006</td>\n",
       "      <td>1.42132</td>\n",
       "      <td>1.48234</td>\n",
       "      <td>1.384560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>472</td>\n",
       "      <td>2.345</td>\n",
       "      <td>2.461</td>\n",
       "      <td>2024</td>\n",
       "      <td>2.284</td>\n",
       "      <td>3846</td>\n",
       "      <td>4133</td>\n",
       "      <td>251</td>\n",
       "      <td>1.915</td>\n",
       "      <td>441</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>1.71550</td>\n",
       "      <td>1.43394</td>\n",
       "      <td>1.35138</td>\n",
       "      <td>1.39319</td>\n",
       "      <td>1.223930</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570</td>\n",
       "      <td>2.404</td>\n",
       "      <td>2.397</td>\n",
       "      <td>2804</td>\n",
       "      <td>1.972</td>\n",
       "      <td>3672</td>\n",
       "      <td>4139</td>\n",
       "      <td>259</td>\n",
       "      <td>2.477</td>\n",
       "      <td>584</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>1.86328</td>\n",
       "      <td>1.64769</td>\n",
       "      <td>1.63455</td>\n",
       "      <td>1.71677</td>\n",
       "      <td>1.520080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>767</td>\n",
       "      <td>2.586</td>\n",
       "      <td>2.261</td>\n",
       "      <td>2702</td>\n",
       "      <td>1.932</td>\n",
       "      <td>4797</td>\n",
       "      <td>4726</td>\n",
       "      <td>304</td>\n",
       "      <td>2.668</td>\n",
       "      <td>574</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>1.65001</td>\n",
       "      <td>1.41541</td>\n",
       "      <td>1.37415</td>\n",
       "      <td>1.67836</td>\n",
       "      <td>1.477770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>745</td>\n",
       "      <td>2.328</td>\n",
       "      <td>2.218</td>\n",
       "      <td>2837</td>\n",
       "      <td>2.366</td>\n",
       "      <td>4447</td>\n",
       "      <td>4080</td>\n",
       "      <td>366</td>\n",
       "      <td>2.390</td>\n",
       "      <td>491</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>1.68188</td>\n",
       "      <td>1.47362</td>\n",
       "      <td>1.43045</td>\n",
       "      <td>1.55640</td>\n",
       "      <td>1.404530</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>579</td>\n",
       "      <td>1.850</td>\n",
       "      <td>2.424</td>\n",
       "      <td>2813</td>\n",
       "      <td>2.450</td>\n",
       "      <td>4213</td>\n",
       "      <td>5238</td>\n",
       "      <td>328</td>\n",
       "      <td>2.361</td>\n",
       "      <td>739</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>27</td>\n",
       "      <td>1.53736</td>\n",
       "      <td>1.34343</td>\n",
       "      <td>1.32522</td>\n",
       "      <td>1.28098</td>\n",
       "      <td>1.154530</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>750</td>\n",
       "      <td>2.304</td>\n",
       "      <td>2.188</td>\n",
       "      <td>2607</td>\n",
       "      <td>1.879</td>\n",
       "      <td>5305</td>\n",
       "      <td>4572</td>\n",
       "      <td>317</td>\n",
       "      <td>2.396</td>\n",
       "      <td>518</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>1.50612</td>\n",
       "      <td>1.31512</td>\n",
       "      <td>1.29116</td>\n",
       "      <td>1.44391</td>\n",
       "      <td>1.300910</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>907</td>\n",
       "      <td>2.239</td>\n",
       "      <td>2.444</td>\n",
       "      <td>3289</td>\n",
       "      <td>2.272</td>\n",
       "      <td>3713</td>\n",
       "      <td>5250</td>\n",
       "      <td>357</td>\n",
       "      <td>2.337</td>\n",
       "      <td>670</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>1.51473</td>\n",
       "      <td>1.39244</td>\n",
       "      <td>1.33926</td>\n",
       "      <td>1.26802</td>\n",
       "      <td>1.159030</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>510</td>\n",
       "      <td>2.573</td>\n",
       "      <td>2.458</td>\n",
       "      <td>2250</td>\n",
       "      <td>2.312</td>\n",
       "      <td>3900</td>\n",
       "      <td>3300</td>\n",
       "      <td>246</td>\n",
       "      <td>2.633</td>\n",
       "      <td>632</td>\n",
       "      <td>...</td>\n",
       "      <td>22</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>1.47965</td>\n",
       "      <td>1.31724</td>\n",
       "      <td>1.29768</td>\n",
       "      <td>1.08829</td>\n",
       "      <td>0.997788</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>521</td>\n",
       "      <td>2.502</td>\n",
       "      <td>2.614</td>\n",
       "      <td>3172</td>\n",
       "      <td>2.510</td>\n",
       "      <td>4309</td>\n",
       "      <td>4388</td>\n",
       "      <td>322</td>\n",
       "      <td>2.644</td>\n",
       "      <td>722</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "      <td>1.66393</td>\n",
       "      <td>1.44226</td>\n",
       "      <td>1.40044</td>\n",
       "      <td>1.59802</td>\n",
       "      <td>1.406340</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ST54SA  ST72TA  ST118TA  ST40SA  ST51TA  ST31SA  ST112SV  ST121SA  \\\n",
       "0       889   2.339    2.422    2832   2.079    6463     4816      368   \n",
       "1       472   2.345    2.461    2024   2.284    3846     4133      251   \n",
       "2       570   2.404    2.397    2804   1.972    3672     4139      259   \n",
       "3       767   2.586    2.261    2702   1.932    4797     4726      304   \n",
       "4       745   2.328    2.218    2837   2.366    4447     4080      366   \n",
       "..      ...     ...      ...     ...     ...     ...      ...      ...   \n",
       "202     579   1.850    2.424    2813   2.450    4213     5238      328   \n",
       "203     750   2.304    2.188    2607   1.879    5305     4572      317   \n",
       "204     907   2.239    2.444    3289   2.272    3713     5250      357   \n",
       "205     510   2.573    2.458    2250   2.312    3900     3300      246   \n",
       "206     521   2.502    2.614    3172   2.510    4309     4388      322   \n",
       "\n",
       "     ST46TA  ST25CV  ...  MMSCORE_m24  MMSCORE_m12  MMSCORE_m06  MMSCORE_sc  \\\n",
       "0     2.609     540  ...           29           30           29          29   \n",
       "1     1.915     441  ...           30           28           29          29   \n",
       "2     2.477     584  ...           28           30           29          28   \n",
       "3     2.668     574  ...           29           30           29          30   \n",
       "4     2.390     491  ...           29           28           28          26   \n",
       "..      ...     ...  ...          ...          ...          ...         ...   \n",
       "202   2.361     739  ...           28           28           28          27   \n",
       "203   2.396     518  ...           30           30           29          29   \n",
       "204   2.337     670  ...           29           29           28          28   \n",
       "205   2.633     632  ...           22           26           26          28   \n",
       "206   2.644     722  ...           20           20           22          27   \n",
       "\n",
       "      CP_MAX  CP_MEDIAN  CP_MEAN   AL_MAX  AL_MEDIAN  label  \n",
       "0    1.59085    1.46006  1.42132  1.48234   1.384560      0  \n",
       "1    1.71550    1.43394  1.35138  1.39319   1.223930      0  \n",
       "2    1.86328    1.64769  1.63455  1.71677   1.520080      0  \n",
       "3    1.65001    1.41541  1.37415  1.67836   1.477770      0  \n",
       "4    1.68188    1.47362  1.43045  1.55640   1.404530      0  \n",
       "..       ...        ...      ...      ...        ...    ...  \n",
       "202  1.53736    1.34343  1.32522  1.28098   1.154530      2  \n",
       "203  1.50612    1.31512  1.29116  1.44391   1.300910      2  \n",
       "204  1.51473    1.39244  1.33926  1.26802   1.159030      2  \n",
       "205  1.47965    1.31724  1.29768  1.08829   0.997788      1  \n",
       "206  1.66393    1.44226  1.40044  1.59802   1.406340      1  \n",
       "\n",
       "[207 rows x 111 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mri_pet_fused_df = pd.concat([mri_data_fusion_df, pet_data_fusion_df],axis = 1, join = 'outer', ignore_index=False, sort=False)\n",
    "mri_pet_fused_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fused, y_fused = np.split(mri_pet_fused_df.to_numpy(), [-1], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fused, X_test_fused, y_train_fused, y_test_fused = train_test_split(X_fused, y_fused, test_size=0.10, random_state=44)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_train_fused = min_max_scaler.fit_transform(X_train_fused)\n",
    "X_test_fused = min_max_scaler.transform(X_test_fused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.71      0.67         7\n",
      "         1.0       0.62      1.00      0.77         5\n",
      "         2.0       1.00      0.56      0.71         9\n",
      "\n",
      "    accuracy                           0.71        21\n",
      "   macro avg       0.75      0.76      0.72        21\n",
      "weighted avg       0.79      0.71      0.71        21\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shrutidudwadkar/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "gnb_fused = GaussianNB().fit(X_train_fused, y_train_fused)\n",
    "gnb_fused_predictions = gnb_fused.predict(X_test_fused)\n",
    "\n",
    "print(\"Classification report: \")\n",
    "print(classification_report(y_test_fused , gnb_fused_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test_fused, gnb_fused_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Modal Results\n",
    "\n",
    "| Model | Precision  | Recall  | F1-Score  | Accuracy \n",
    "|:-:|:-:|:-:|:-:|:-:|\n",
    "| Multi-modal Late/Classifier fusion model  | 0.69 | 0.73  | 0.70  | 0.69  |\n",
    "| **Multi-modal early fusion model**  | **0.75** | **0.76**  | **0.72** | **0.71**  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
